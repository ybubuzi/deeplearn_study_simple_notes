"""
ç¥ç»ç½‘ç»œæƒé‡ç»“æ„è¯¦è§£
è§£é‡Šä¸ºä»€ä¹ˆéœ€è¦ weights[0][0] æ¥è·å–æƒé‡å€¼
"""

import tensorflow as tf
import numpy as np

print("ğŸ” ç¥ç»ç½‘ç»œæƒé‡ç»“æ„è§£æ")
print("=" * 50)

# 1. åˆ›å»ºç®€å•çš„çº¿æ€§å›å½’æ¨¡å‹
print("\n1. åˆ›å»ºæ¨¡å‹å¹¶æŸ¥çœ‹æƒé‡ç»“æ„")
print("-" * 30)

model = tf.keras.Sequential([
    tf.keras.layers.Dense(1, input_shape=(1,), name='linear_layer')
])

# ç¼–è¯‘æ¨¡å‹ï¼ˆè¿™ä¼šåˆå§‹åŒ–æƒé‡ï¼‰
model.compile(optimizer='adam', loss='mse')

# è·å–æƒé‡
weights, bias = model.layers[0].get_weights()

print("ğŸ“Š æƒé‡è¯¦ç»†ä¿¡æ¯:")
print(f"weights ç±»å‹: {type(weights)}")
print(f"weights å½¢çŠ¶: {weights.shape}")
print(f"weights å†…å®¹:\n{weights}")
print(f"weights ç»´åº¦æ•°: {weights.ndim}")

print(f"\nbias ç±»å‹: {type(bias)}")
print(f"bias å½¢çŠ¶: {bias.shape}")
print(f"bias å†…å®¹: {bias}")
print(f"bias ç»´åº¦æ•°: {bias.ndim}")

# 2. è§£é‡Šæƒé‡çŸ©é˜µçš„ç»“æ„
print("\n2. æƒé‡çŸ©é˜µç»“æ„è§£é‡Š")
print("-" * 30)

print("ğŸ§  Denseå±‚çš„æ•°å­¦åŸç†:")
print("Denseå±‚æ‰§è¡Œçš„è¿ç®—: output = input Ã— weights + bias")
print()
print("å¯¹äºæˆ‘ä»¬çš„çº¿æ€§å›å½’:")
print("- è¾“å…¥ç»´åº¦: 1 (ä¸€ä¸ªç‰¹å¾)")
print("- è¾“å‡ºç»´åº¦: 1 (ä¸€ä¸ªé¢„æµ‹å€¼)")
print("- æ‰€ä»¥æƒé‡çŸ©é˜µå½¢çŠ¶: (è¾“å…¥ç»´åº¦, è¾“å‡ºç»´åº¦) = (1, 1)")
print()
print("æƒé‡çŸ©é˜µç»“æ„:")
print("weights = [[w]]  # 2Dæ•°ç»„ï¼Œå½¢çŠ¶ä¸º(1,1)")
print("          â†‘")
print("          è¿™å°±æ˜¯æˆ‘ä»¬è¦çš„æƒé‡å€¼")

# 3. ä¸åŒç½‘ç»œç»“æ„çš„æƒé‡å¯¹æ¯”
print("\n3. ä¸åŒç½‘ç»œç»“æ„çš„æƒé‡å¯¹æ¯”")
print("-" * 30)

# åˆ›å»ºä¸åŒç»“æ„çš„ç½‘ç»œ
models = {
    "1è¾“å…¥â†’1è¾“å‡º": tf.keras.Sequential([tf.keras.layers.Dense(1, input_shape=(1,))]),
    "1è¾“å…¥â†’3è¾“å‡º": tf.keras.Sequential([tf.keras.layers.Dense(3, input_shape=(1,))]),
    "2è¾“å…¥â†’1è¾“å‡º": tf.keras.Sequential([tf.keras.layers.Dense(1, input_shape=(2,))]),
    "2è¾“å…¥â†’3è¾“å‡º": tf.keras.Sequential([tf.keras.layers.Dense(3, input_shape=(2,))])
}

for name, model in models.items():
    model.compile(optimizer='adam', loss='mse')
    weights, bias = model.layers[0].get_weights()
    print(f"{name}:")
    print(f"  æƒé‡å½¢çŠ¶: {weights.shape}")
    print(f"  åç½®å½¢çŠ¶: {bias.shape}")
    print(f"  æƒé‡å†…å®¹:\n{weights}")
    print()

# 4. è®¿é—®æƒé‡çš„ä¸åŒæ–¹å¼
print("\n4. è®¿é—®æƒé‡çš„ä¸åŒæ–¹å¼")
print("-" * 30)

# é‡æ–°è·å–æˆ‘ä»¬çš„çº¿æ€§å›å½’æ¨¡å‹æƒé‡
model_simple = tf.keras.Sequential([
    tf.keras.layers.Dense(1, input_shape=(1,))
])
model_simple.compile(optimizer='adam', loss='mse')
weights, bias = model_simple.layers[0].get_weights()

print("æƒé‡çŸ©é˜µ:", weights)
print("æƒé‡çŸ©é˜µå½¢çŠ¶:", weights.shape)
print()

print("ğŸ” ä¸åŒçš„è®¿é—®æ–¹å¼:")
print(f"weights[0][0] = {weights[0][0]}")  # æ ‡å‡†æ–¹å¼
print(f"weights[0, 0] = {weights[0, 0]}")  # NumPyé£æ ¼
print(f"weights.item() = {weights.item()}")  # æå–æ ‡é‡å€¼
print(f"weights.flatten()[0] = {weights.flatten()[0]}")  # å±•å¹³åå–ç¬¬ä¸€ä¸ª

print("\nğŸ’¡ ä¸ºä»€ä¹ˆç”¨ weights[0][0]:")
print("1. weights æ˜¯å½¢çŠ¶ä¸º (1,1) çš„2Dæ•°ç»„")
print("2. ç¬¬ä¸€ä¸ª [0] é€‰æ‹©ç¬¬ä¸€è¡Œï¼ˆä¹Ÿæ˜¯å”¯ä¸€ä¸€è¡Œï¼‰")
print("3. ç¬¬äºŒä¸ª [0] é€‰æ‹©ç¬¬ä¸€åˆ—ï¼ˆä¹Ÿæ˜¯å”¯ä¸€ä¸€åˆ—ï¼‰")
print("4. ç»“æœå¾—åˆ°æ ‡é‡å€¼ï¼ˆå•ä¸ªæ•°å­—ï¼‰")

# 5. å®é™…è®­ç»ƒåçš„æƒé‡
print("\n5. è®­ç»ƒåçš„æƒé‡å˜åŒ–")
print("-" * 30)

# ç”Ÿæˆè®­ç»ƒæ•°æ®
np.random.seed(42)
X_train = np.random.uniform(-1, 1, 100).reshape(-1, 1)
y_train = 2 * X_train.flatten() + 1 + np.random.normal(0, 0.1, 100)

print("è®­ç»ƒå‰çš„æƒé‡:")
weights_before, bias_before = model_simple.layers[0].get_weights()
print(f"æƒé‡çŸ©é˜µ: {weights_before}")
print(f"æƒé‡å€¼: {weights_before[0][0]:.6f}")
print(f"åç½®å€¼: {bias_before[0]:.6f}")

# è®­ç»ƒæ¨¡å‹
print("\nå¼€å§‹è®­ç»ƒ...")
model_simple.fit(X_train, y_train, epochs=50, verbose=0)

print("\nè®­ç»ƒåçš„æƒé‡:")
weights_after, bias_after = model_simple.layers[0].get_weights()
print(f"æƒé‡çŸ©é˜µ: {weights_after}")
print(f"æƒé‡å€¼: {weights_after[0][0]:.6f} (ç›®æ ‡: 2.0)")
print(f"åç½®å€¼: {bias_after[0]:.6f} (ç›®æ ‡: 1.0)")

# 6. å¤šå±‚ç½‘ç»œçš„æƒé‡ç»“æ„
print("\n6. å¤šå±‚ç½‘ç»œçš„æƒé‡ç»“æ„")
print("-" * 30)

# åˆ›å»ºå¤šå±‚ç½‘ç»œ
multi_layer_model = tf.keras.Sequential([
    tf.keras.layers.Dense(3, input_shape=(2,), name='hidden_layer'),
    tf.keras.layers.Dense(1, name='output_layer')
])
multi_layer_model.compile(optimizer='adam', loss='mse')

print("å¤šå±‚ç½‘ç»œç»“æ„:")
for i, layer in enumerate(multi_layer_model.layers):
    weights, bias = layer.get_weights()
    print(f"ç¬¬{i+1}å±‚ ({layer.name}):")
    print(f"  æƒé‡å½¢çŠ¶: {weights.shape}")
    print(f"  åç½®å½¢çŠ¶: {bias.shape}")
    print(f"  æƒé‡çŸ©é˜µ:\n{weights}")
    print()

# 7. JavaScriptç±»æ¯”ç†è§£
print("\n7. JavaScriptç±»æ¯”ç†è§£")
print("-" * 30)

print("ğŸ”— ç”¨JavaScriptç±»æ¯”ç†è§£:")
print("""
// å¦‚æœç”¨JavaScriptè¡¨ç¤ºæƒé‡çŸ©é˜µ
const weights = [
    [0.5]  // ç¬¬ä¸€è¡Œï¼Œç¬¬ä¸€åˆ—
];

// è®¿é—®æƒé‡å€¼
const weightValue = weights[0][0];  // 0.5

// ç±»ä¼¼äºPythonçš„
// weight_value = weights[0][0]
""")

print("ğŸ¯ æ€»ç»“:")
print("1. Denseå±‚çš„æƒé‡æ€»æ˜¯2DçŸ©é˜µï¼Œå³ä½¿åªæœ‰ä¸€ä¸ªæƒé‡")
print("2. å½¢çŠ¶ä¸º (è¾“å…¥ç»´åº¦, è¾“å‡ºç»´åº¦)")
print("3. å¯¹äºçº¿æ€§å›å½’: (1, 1) - 1ä¸ªè¾“å…¥ï¼Œ1ä¸ªè¾“å‡º")
print("4. weights[0][0] æ˜¯è®¿é—®è¿™ä¸ª2DçŸ©é˜µä¸­å”¯ä¸€å…ƒç´ çš„æ–¹å¼")
print("5. è¿™ç§è®¾è®¡ä¿æŒäº†çŸ©é˜µè¿ç®—çš„ä¸€è‡´æ€§")

# 8. å¸¸è§é”™è¯¯æ¼”ç¤º
print("\n8. å¸¸è§é”™è¯¯æ¼”ç¤º")
print("-" * 30)

print("âŒ å¸¸è§é”™è¯¯:")
try:
    # é”™è¯¯ï¼šç›´æ¥æŠŠweightså½“ä½œæ ‡é‡
    wrong_value = weights + 1  # è¿™ä¼šè¿›è¡Œæ•°ç»„è¿ç®—ï¼Œä¸æ˜¯æ ‡é‡è¿ç®—
    print(f"weights + 1 = {wrong_value}")
    print("è¿™æ˜¯æ•°ç»„è¿ç®—ï¼Œä¸æ˜¯æˆ‘ä»¬æƒ³è¦çš„æ ‡é‡è¿ç®—")
except Exception as e:
    print(f"é”™è¯¯: {e}")

print("\nâœ… æ­£ç¡®åšæ³•:")
correct_value = weights[0][0] + 1  # å…ˆæå–æ ‡é‡ï¼Œå†è¿ç®—
print(f"weights[0][0] + 1 = {correct_value}")
print("è¿™æ˜¯æ ‡é‡è¿ç®—ï¼Œç¬¦åˆæˆ‘ä»¬çš„é¢„æœŸ")

print("\n" + "=" * 50)
print("ğŸ“ å…³é”®ç†è§£:")
print("æƒé‡çŸ©é˜µçš„è®¾è®¡æ˜¯ä¸ºäº†æ”¯æŒçŸ©é˜µè¿ç®—ï¼Œ")
print("å³ä½¿åªæœ‰ä¸€ä¸ªæƒé‡ï¼Œä¹Ÿè¦ä¿æŒçŸ©é˜µçš„ç»“æ„ï¼")
print("=" * 50)
