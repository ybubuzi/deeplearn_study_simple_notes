"""
TensorFlow æ·±åº¦å­¦ä¹ å…¥é—¨ç¤ºä¾‹ 4: ç®€å•æ—¶åºé¢„æµ‹
ç”¨æœ€ç®€å•çš„æ–¹å¼ç†è§£æ—¶åºæ•°æ®å’ŒRNN
é¢„æµ‹è‚¡ä»·èµ°åŠ¿ï¼ˆæ¨¡æ‹Ÿæ•°æ®ï¼‰
"""

import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt

# è®¾ç½®ä¸­æ–‡å­—ä½“æ˜¾ç¤º
plt.rcParams['font.sans-serif'] = ['SimHei']
plt.rcParams['axes.unicode_minus'] = False

print("TensorFlowç‰ˆæœ¬:", tf.__version__)
print("=" * 60)
print("ğŸ“ˆ ç®€å•æ—¶åºé¢„æµ‹å…¥é—¨")
print("=" * 60)

# 1. ç”Ÿæˆæ¨¡æ‹Ÿçš„è‚¡ä»·æ•°æ®
print("\n1. ç”Ÿæˆæ¨¡æ‹Ÿè‚¡ä»·æ•°æ®...")

def create_stock_data(days=1000):
    """
    åˆ›å»ºæ¨¡æ‹Ÿè‚¡ä»·æ•°æ®
    æ¨¡æ‹Ÿä¸€ä¸ªæœ‰è¶‹åŠ¿å’Œæ³¢åŠ¨çš„è‚¡ä»·åºåˆ—
    """
    np.random.seed(42)  # ç¡®ä¿ç»“æœå¯é‡ç°
    
    # åŸºç¡€è¶‹åŠ¿ï¼šç¼“æ…¢ä¸Šæ¶¨
    trend = np.linspace(100, 150, days)
    
    # æ·»åŠ éšæœºæ³¢åŠ¨
    noise = np.random.normal(0, 5, days)
    
    # æ·»åŠ å‘¨æœŸæ€§æ³¢åŠ¨ï¼ˆæ¨¡æ‹Ÿå¸‚åœºå‘¨æœŸï¼‰
    cycle = 10 * np.sin(np.linspace(0, 4*np.pi, days))
    
    # åˆæˆæœ€ç»ˆè‚¡ä»·
    stock_price = trend + cycle + noise
    
    return stock_price

# ç”Ÿæˆ1000å¤©çš„è‚¡ä»·æ•°æ®
stock_prices = create_stock_data(1000)
print(f"ç”Ÿæˆäº† {len(stock_prices)} å¤©çš„è‚¡ä»·æ•°æ®")
print(f"ä»·æ ¼èŒƒå›´: {stock_prices.min():.2f} - {stock_prices.max():.2f}")

# 2. å¯è§†åŒ–åŸå§‹æ•°æ®
plt.figure(figsize=(12, 4))
plt.plot(stock_prices[:200], label='è‚¡ä»·')  # åªæ˜¾ç¤ºå‰200å¤©
plt.title('æ¨¡æ‹Ÿè‚¡ä»·æ•°æ®ï¼ˆå‰200å¤©ï¼‰')
plt.xlabel('å¤©æ•°')
plt.ylabel('è‚¡ä»·')
plt.legend()
plt.grid(True)
plt.show()

# 3. å‡†å¤‡æ—¶åºæ•°æ®
print("\n2. å‡†å¤‡æ—¶åºè®­ç»ƒæ•°æ®...")

def create_sequences(data, seq_length):
    """
    å°†æ—¶åºæ•°æ®è½¬æ¢ä¸ºç›‘ç£å­¦ä¹ æ ¼å¼
    
    ä¾‹å¦‚ï¼šç”¨è¿‡å»5å¤©çš„ä»·æ ¼é¢„æµ‹ç¬¬6å¤©çš„ä»·æ ¼
    [1,2,3,4,5] -> X=[1,2,3,4,5], y=6
    [2,3,4,5,6] -> X=[2,3,4,5,6], y=7
    """
    X, y = [], []
    
    for i in range(len(data) - seq_length):
        # è¾“å…¥ï¼šè¿‡å»seq_lengthå¤©çš„ä»·æ ¼
        X.append(data[i:i + seq_length])
        # è¾“å‡ºï¼šä¸‹ä¸€å¤©çš„ä»·æ ¼
        y.append(data[i + seq_length])
    
    return np.array(X), np.array(y)

# ä½¿ç”¨è¿‡å»10å¤©é¢„æµ‹ä¸‹ä¸€å¤©
sequence_length = 10
X, y = create_sequences(stock_prices, sequence_length)

print(f"åºåˆ—é•¿åº¦: {sequence_length}")
print(f"è®­ç»ƒæ ·æœ¬æ•°: {len(X)}")
print(f"Xå½¢çŠ¶: {X.shape}")  # (æ ·æœ¬æ•°, åºåˆ—é•¿åº¦)
print(f"yå½¢çŠ¶: {y.shape}")  # (æ ·æœ¬æ•°,)

# æ˜¾ç¤ºå‡ ä¸ªä¾‹å­
print("\næ•°æ®ç¤ºä¾‹:")
for i in range(3):
    print(f"æ ·æœ¬{i+1}: è¾“å…¥={X[i][:5]}... -> è¾“å‡º={y[i]:.2f}")

# 4. æ•°æ®æ ‡å‡†åŒ–
print("\n3. æ•°æ®æ ‡å‡†åŒ–...")

# è®¡ç®—å‡å€¼å’Œæ ‡å‡†å·®ï¼ˆåªç”¨è®­ç»ƒæ•°æ®ï¼‰
train_size = int(0.8 * len(X))
X_train, X_test = X[:train_size], X[train_size:]
y_train, y_test = y[:train_size], y[train_size:]

# æ ‡å‡†åŒ–ï¼ˆé‡è¦ï¼šé˜²æ­¢æ¢¯åº¦çˆ†ç‚¸ï¼‰
mean_price = X_train.mean()
std_price = X_train.std()

X_train_scaled = (X_train - mean_price) / std_price
X_test_scaled = (X_test - mean_price) / std_price
y_train_scaled = (y_train - mean_price) / std_price
y_test_scaled = (y_test - mean_price) / std_price

print(f"è®­ç»ƒé›†å¤§å°: {len(X_train)}")
print(f"æµ‹è¯•é›†å¤§å°: {len(X_test)}")
print(f"æ•°æ®å‡å€¼: {mean_price:.2f}")
print(f"æ•°æ®æ ‡å‡†å·®: {std_price:.2f}")

# 5. æ„å»ºç®€å•çš„RNNæ¨¡å‹
print("\n4. æ„å»ºRNNæ¨¡å‹...")

model = tf.keras.Sequential([
    # ç®€å•RNNå±‚ï¼šå¤„ç†æ—¶åºæ•°æ®
    tf.keras.layers.SimpleRNN(50, input_shape=(sequence_length, 1), name='rnn_layer'),
    
    # è¾“å‡ºå±‚ï¼šé¢„æµ‹ä¸‹ä¸€ä¸ªä»·æ ¼
    tf.keras.layers.Dense(1, name='output_layer')
])

# ç¼–è¯‘æ¨¡å‹
model.compile(
    optimizer='adam',
    loss='mse',  # å‡æ–¹è¯¯å·®ï¼Œé€‚åˆå›å½’é—®é¢˜
    metrics=['mae']  # å¹³å‡ç»å¯¹è¯¯å·®
)

print("æ¨¡å‹ç»“æ„:")
model.summary()

# 6. è®­ç»ƒæ¨¡å‹
print("\n5. å¼€å§‹è®­ç»ƒ...")

# é‡å¡‘è¾“å…¥æ•°æ®ä¸º3Dæ ¼å¼ (æ ·æœ¬æ•°, æ—¶é—´æ­¥, ç‰¹å¾æ•°)
X_train_reshaped = X_train_scaled.reshape(X_train_scaled.shape[0], X_train_scaled.shape[1], 1)
X_test_reshaped = X_test_scaled.reshape(X_test_scaled.shape[0], X_test_scaled.shape[1], 1)

history = model.fit(
    X_train_reshaped, y_train_scaled,
    epochs=20,  # è®­ç»ƒ20è½®
    batch_size=32,
    validation_data=(X_test_reshaped, y_test_scaled),
    verbose=1
)

# 7. è¯„ä¼°æ¨¡å‹
print("\n6. æ¨¡å‹è¯„ä¼°...")
test_loss, test_mae = model.evaluate(X_test_reshaped, y_test_scaled, verbose=0)
print(f"æµ‹è¯•æŸå¤±: {test_loss:.4f}")
print(f"æµ‹è¯•MAE: {test_mae:.4f}")

# 8. è¿›è¡Œé¢„æµ‹
print("\n7. è¿›è¡Œé¢„æµ‹...")
predictions_scaled = model.predict(X_test_reshaped, verbose=0)

# åæ ‡å‡†åŒ–é¢„æµ‹ç»“æœ
predictions = predictions_scaled * std_price + mean_price
actual = y_test

# è®¡ç®—é¢„æµ‹å‡†ç¡®æ€§
mae = np.mean(np.abs(predictions.flatten() - actual))
print(f"é¢„æµ‹å¹³å‡ç»å¯¹è¯¯å·®: {mae:.2f}")

# 9. å¯è§†åŒ–ç»“æœ
plt.figure(figsize=(15, 10))

# è®­ç»ƒè¿‡ç¨‹
plt.subplot(2, 2, 1)
plt.plot(history.history['loss'], label='è®­ç»ƒæŸå¤±')
plt.plot(history.history['val_loss'], label='éªŒè¯æŸå¤±')
plt.title('æ¨¡å‹è®­ç»ƒè¿‡ç¨‹')
plt.xlabel('è®­ç»ƒè½®æ•°')
plt.ylabel('æŸå¤±å€¼')
plt.legend()
plt.grid(True)

# é¢„æµ‹ vs å®é™…
plt.subplot(2, 2, 2)
plt.plot(actual[:100], label='å®é™…ä»·æ ¼', alpha=0.7)
plt.plot(predictions[:100], label='é¢„æµ‹ä»·æ ¼', alpha=0.7)
plt.title('é¢„æµ‹ç»“æœå¯¹æ¯”ï¼ˆå‰100ä¸ªæµ‹è¯•æ ·æœ¬ï¼‰')
plt.xlabel('æ ·æœ¬')
plt.ylabel('è‚¡ä»·')
plt.legend()
plt.grid(True)

# é¢„æµ‹è¯¯å·®åˆ†å¸ƒ
plt.subplot(2, 2, 3)
errors = predictions.flatten() - actual
plt.hist(errors, bins=30, alpha=0.7)
plt.title('é¢„æµ‹è¯¯å·®åˆ†å¸ƒ')
plt.xlabel('è¯¯å·®')
plt.ylabel('é¢‘æ¬¡')
plt.grid(True)

# æ•£ç‚¹å›¾ï¼šé¢„æµ‹ vs å®é™…
plt.subplot(2, 2, 4)
plt.scatter(actual, predictions.flatten(), alpha=0.5)
plt.plot([actual.min(), actual.max()], [actual.min(), actual.max()], 'r--', lw=2)
plt.title('é¢„æµ‹å€¼ vs å®é™…å€¼')
plt.xlabel('å®é™…å€¼')
plt.ylabel('é¢„æµ‹å€¼')
plt.grid(True)

plt.tight_layout()
plt.show()

# 10. æœªæ¥é¢„æµ‹ç¤ºä¾‹
print("\n8. æœªæ¥é¢„æµ‹ç¤ºä¾‹...")

# ä½¿ç”¨æœ€å10å¤©çš„æ•°æ®é¢„æµ‹ä¸‹ä¸€å¤©
last_sequence = X_test_scaled[-1:].reshape(1, sequence_length, 1)
next_prediction_scaled = model.predict(last_sequence, verbose=0)
next_prediction = next_prediction_scaled * std_price + mean_price

print(f"æœ€å10å¤©ä»·æ ¼: {X_test[-1]}")
print(f"é¢„æµ‹ä¸‹ä¸€å¤©ä»·æ ¼: {next_prediction[0][0]:.2f}")
print(f"å®é™…ä¸‹ä¸€å¤©ä»·æ ¼: {y_test[-1]:.2f}")
print(f"é¢„æµ‹è¯¯å·®: {abs(next_prediction[0][0] - y_test[-1]):.2f}")

print("\n" + "=" * 60)
print("âœ… ç®€å•æ—¶åºé¢„æµ‹å®Œæˆï¼")
print("=" * 60)
print("ğŸ“š å­¦åˆ°çš„æ¦‚å¿µ:")
print("1. æ—¶åºæ•°æ®çš„ç‰¹ç‚¹ï¼šå½“å‰å€¼ä¾èµ–äºå†å²å€¼")
print("2. åºåˆ—æ•°æ®çš„å‡†å¤‡ï¼šæ»‘åŠ¨çª—å£æ–¹æ³•")
print("3. RNNçš„åŸºæœ¬åŸç†ï¼šå¤„ç†åºåˆ—æ•°æ®")
print("4. æ•°æ®æ ‡å‡†åŒ–çš„é‡è¦æ€§")
print("5. æ—¶åºé¢„æµ‹çš„è¯„ä¼°æ–¹æ³•")
print("=" * 60)
